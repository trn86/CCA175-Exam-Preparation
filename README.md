# CCA175-Exam-Preparation

Recently i cleared my CCA175 Spark and Hadoop Developer Certification. I had a good time going through the learning journey to passing the exam.

## Required Skills

Transform, Stage, and Store
Convert a set of data values in a given format stored in HDFS into new data values or a new data format and write them into HDFS.
•	Load data from HDFS for use in Spark applications
•	Write the results back into HDFS using Spark
•	Read and write files in a variety of file formats
•	Perform standard extract, transform, load (ETL) processes on data using the Spark API

Use Spark SQL to interact with the metastore programmatically in your applications. Generate reports by using queries against loaded data.
•	Use metastore tables as an input source or an output sink for Spark applications
•	Understand the fundamentals of querying datasets in Spark
•	Filter data using Spark
•	Write queries that calculate aggregate statistics
•	Join disparate datasets using Spark
•	Produce ranked or sorted data

Here are some areas the exam excepts you to have skills i feel is good to have to clear the exam
1. Comfortable on hadoop and linux commands
2. Your ability to read, process and write data with Apache Spark 2.0+.
3. Ability to read data from various sources like csv,text file,json,avro,parquet,database and hive,etc.
4. Read data with the desired datatypes/schema specified in the problem statement.
5. Read data with different delimiters, with or without header.
6. Join datasets, perform filters and standard sql functions like concat,data formatting ,data appending.
7. Perform aggregations using group by like avg,sum,max,count.
8. Create new columns and their data using exisiting columns data.
9. Performing analytical function using Window functions like dense rank,rank,ntile,etc.
10. Ability to perform operations using hive and spark or hdfs and spark,etc.
11. Knowledge of coalesce
12. You ability to write code with dataframes as well as spark sql.

## Exam Format

Exam is 2 hours long
Exam has 8 - 12 questions based on spark datamframes/dataset (There is not much difference in the latest 2.4 Spark onwards)
You are given a problem to read data with path provided and you need to read data, perform some operations and write output to hdfs/hive as mentioned in the latest exam format.
